{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOx8ic4Q6yzhD4T/vodhhSF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saicharan7479/pytorch-notes/blob/main/petrol_price_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this text is ai generated i mean i wrote it and it removed errors and made it readable :)\n",
        "\n",
        "First, we need to take the bias and weight parameters.\n",
        "\n",
        "Then, we sort the data from oldest to newest.\n",
        "\n",
        "Next, we remove any null values using the dropna() function.\n",
        "\n",
        "After that, we need to arrange the data line by line to make it easier to normalize.\n",
        "\n",
        "We then normalize the data (normalization logic taken from ChatGPT).\n",
        "\n",
        "Once normalized, we convert the data into tensors.\n",
        "\n",
        "We split the data using the 80/20 rule — 80% for training and 20% for testing.\n",
        "\n",
        "Next, we define the data (training and test datasets).\n",
        "\n",
        "After defining the data, we add a loss function and an optimizer:\n",
        "\n",
        "Why do we use a loss function?\n",
        "To quantify the error between the model's predictions and the actual target values.\n",
        "\n",
        "What does the optimizer do?\n",
        "It tries to minimize the loss function by adjusting the model's parameters.\n",
        "\n",
        "Note: Loss function, cost function — these terms are often used interchangeably.\n",
        "\n",
        "Then, we train the model.\n",
        "\n",
        "I trained the model for 300 predictions, with evaluations at 50, 100, 150, 200, and 250.\n",
        "\n",
        "After training, we move to the evaluation phase:\n",
        "\n",
        "model.eval() is used to switch the model to evaluation mode, stopping any further training.\n",
        "\n",
        "We use with torch.inference_mode(): to make predictions without tracking gradients, which makes it faster and more memory-efficient.\n",
        "\n"
      ],
      "metadata": {
        "id": "ortaL-ALg9YI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#petrol predictor by using machine learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "yi6Q-CEREExG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/petrol[1].csv\")"
      ],
      "metadata": {
        "id": "ZQOSQ7MDEKgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#in normal their will be start stop and step we did -1 because we need data from oldest to newest the current data is from newest to oldest\n",
        "df = df.iloc[::-1].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fJcX3UpqEMeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this shift operation goes down in the row line by line\n",
        "df[\"Delhi_yesterday\"] = df[\"Delhi\"].shift(1)"
      ],
      "metadata": {
        "id": "FJjP0LMCEQNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removing null values\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "MU68527hEXlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this are like bias and weight were we have seen at daniel video\n",
        "X = df[[\"Delhi_yesterday\", \"Kolkata\", \"Mumbai\", \"Chennai\"]].values\n",
        "y = df[[\"Delhi\"]].values"
      ],
      "metadata": {
        "id": "QFCc6UwFEc35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual normalization (Min-Max)\n",
        "X_min = X.min(axis=0)\n",
        "X_max = X.max(axis=0)     # got error here so used used normalization here the colab itself recommended this thing, it basically sort things from top to bottom\n",
        "X_scaled = (X - X_min) / (X_max - X_min)"
      ],
      "metadata": {
        "id": "l5yv04nEEfN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting into tensors\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32) #we take this here as float32 beacuse X is like tensor it gives us long or float 64 we need to convert into flaot 32\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "QOiQ1O5tEkTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting into 80 20 80-training 20-testing\n",
        "split_index = int(0.8 * len(X_tensor))\n",
        "X_train = X_tensor[:split_index]\n",
        "X_test = X_tensor[split_index:]    # copied from daniel brouk\n",
        "y_train = y_tensor[:split_index]\n",
        "y_test = y_tensor[split_index:]"
      ],
      "metadata": {
        "id": "LFG56HlkEpG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class PetrolPricePredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PetrolPricePredictor, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(4, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = PetrolPricePredictor()"
      ],
      "metadata": {
        "id": "3MBDjzlZErh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function or criterion and optimizer\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "o6sInuC8ExfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(300):\n",
        "    model.train()\n",
        "    output = model(X_train)\n",
        "    loss = criterion(output, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() #it is like to improve if the result the answer is wrong then it sets automatically\n",
        "    optimizer.step() # this backward will cahnge the values if we want changed data we need to use this thing\n",
        "\n",
        "    if (epoch + 1) % 50 == 0: # i set this for check this 300 times like first 50 then 100 and 150............\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efEw2hKOEyst",
        "outputId": "7bd7e799-8ba1-4a83-fb79-17df82af74ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Loss: 67.5034\n",
            "Epoch 100, Loss: 67.5034\n",
            "Epoch 150, Loss: 67.5034\n",
            "Epoch 200, Loss: 67.5034\n",
            "Epoch 250, Loss: 67.5034\n",
            "Epoch 300, Loss: 67.5034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval() # this will stop traning then it starts predicting\n",
        "with torch.inference_mode(): #start predicting\n",
        "    predictions = model(X_test)\n",
        "    for i in range(5):\n",
        "        actual = y_test[i].item()\n",
        "        predicted = predictions[i].item()\n",
        "        print(f\"Predicted: {predicted:.2f} | Actual: {actual:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgvFQdznE1VY",
        "outputId": "4d641592-1b9f-4ec0-bc1c-34a59fca9fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 0.00 | Actual: 73.16\n",
            "Predicted: 0.00 | Actual: 73.31\n",
            "Predicted: 0.00 | Actual: 73.38\n",
            "Predicted: 0.00 | Actual: 73.38\n",
            "Predicted: 0.00 | Actual: 73.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mape = torch.mean(torch.abs((y_test - predictions) / y_test)) * 100\n",
        "print(f\"\\nMean Absolute Percentage Error (MAPE): {mape.item():.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-1zkMD8raGe",
        "outputId": "6e442d80-09f8-4ec1-d1a8-7c42a0e16919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mean Absolute Percentage Error (MAPE): 100.00%\n"
          ]
        }
      ]
    }
  ]
}